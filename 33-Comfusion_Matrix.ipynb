{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1ttDEmcxCT8q1gP_h981p9aQl3uweTS0i","timestamp":1727967058757}],"authorship_tag":"ABX9TyO2UbdEDECZeSK2QK+vM+lZ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["#Confusion Matrix\n","\n","In this notebook we will learn about confusion matrix which is a performance measurement tool for classification models."],"metadata":{"id":"a2YlYClbj1zs"}},{"cell_type":"markdown","source":["A **confusion matrix** is a performance measurement tool for classification models. It summarizes the predictions of a model on a set of test data for which the true values are known. The matrix helps to visualize how well a classification model is performing by showing the counts of actual vs. predicted classifications across all possible classes.\n","\n"],"metadata":{"id":"gilF_r1AjzbJ"}},{"cell_type":"markdown","source":["##**Confusion matrix for Structure**\n","\n","Consider a binary classification task where we only have two classes: positive and negative. A confusion matrix for such task has the following structure:\n","\n","\n","\n","**(I) Binary Classification**\n","\n","$$\n","\\begin{array}{|c|c|c|}\n","\\hline\n"," & \\textbf{Predicted Positive} & \\textbf{Predicted Negative} \\\\\n","\\hline\n","\\textbf{Actual Positive} & \\text{True Positive (TP)} & \\text{False Negative (FN)} \\\\\n","\\hline\n","\\textbf{Actual Negative} & \\text{False Positive (FP)} & \\text{True Negative (TN)} \\\\\n","\\hline\n","\\end{array}\n","$$\n","\n","\n","__Components:__\n","\n","1. **True Positive (TP)**: The model correctly predicted the positive class.\n","2. **False Negative (FN)**: The model predicted negative, but the actual class was positive (also called Type II error).\n","3. **False Positive (FP)**: The model predicted positive, but the actual class was negative (also called Type I error).\n","4. **True Negative (TN)**: The model correctly predicted the negative class.\n","\n","\n","\n","**(II) Multiclass Classification**\n","\n","In multiclass problems, the confusion matrix extends to more classes. Each row corresponds to the actual class, and each column corresponds to the predicted class.\n","\n","For instance, for three classes (A, B, C), the confusion matrix could look like:\n","\n","$$\n","\\begin{array}{|c|c|c|c|}\n","\\hline\n"," & \\textbf{Predicted A} & \\textbf{Predicted B} & \\textbf{Predicted C} \\\\\n","\\hline\n","\\textbf{Actual A} & TP_A & FP_B & FP_C \\\\\n","\\hline\n","\\textbf{Actual B} & FN_A & TP_B & FP_C \\\\\n","\\hline\n","\\textbf{Actual C} & FN_A & FN_B & TP_C \\\\\n","\\hline\n","\\end{array}\n","$$\n"],"metadata":{"id":"wrW14Iu8kVo4"}},{"cell_type":"markdown","source":["## **How to use confusion matrix to develop peformance measurement**"],"metadata":{"id":"Xrkuq1vPkO1D"}},{"cell_type":"markdown","source":["**Accuracy**: Measures the proportion of __correct predictions__ (both positive and negative) among all predictions. It is calculated as:\n","\n","$$\n","\\text{Accuracy} = \\frac{TP + TN}{TP + TN + FP + FN}\n","$$\n","\n","\n"," - __When to Use:__ When both false positives and false negatives are equally important, and the class distribution is balanced.\n","\n","\n"," - __When to Avoid:__ In cases of class imbalance, as it may give misleading results.\n","\n","---\n","\n","\n","**Precision**: Measures the proportion of __correctly predicted positive__ observations out of all observations predicted as positive. It is calculated as:\n","\n","$$\n","\\text{Precision} = \\frac{TP}{TP + FP}\n","$$\n","\n","\n","\n"," - __When to Use:__ Use precision when the cost of false positives is high. For example, in spam detection, you want to avoid classifying legitimate emails as spam. Precision focuses on the quality of positive predictions.\n","\n","\n"," - __When to Avoid:__ When false negatives are more concerning, as precision doesn’t consider how many true positives were missed (i.e., it does not penalize for false negatives).\n","\n","---\n","\n","**Recall (Sensitivity)**: Measures the proportion of __actual positives that were correctly identified__. It is calculated as:\n","\n","$$\n","\\text{Recall} = \\frac{TP}{TP + FN}\n","$$\n","\n","\n","- __When to Use:__ Use recall when false negatives are costly. For example, in medical diagnoses, you want to ensure that no actual disease case goes undetected (minimizing false negatives). Recall is crucial when missing positives is more serious than falsely identifying negatives.\n","\n","\n","- __Avoid:__ When you want a balance between false positives and false negatives, as recall does not account for how many false positives there are.\n","\n","---\n","\n","**F1 Score**: The harmonic mean of precision and recall, providing a balance between them:\n","\n","$$\n","\\text{F1 Score} = 2 \\cdot \\frac{\\text{Precision} \\cdot \\text{Recall}}{\\text{Precision} + \\text{Recall}}\n","$$\n","\n","   - **Use**: When you need a balance between precision and recall, especially in imbalanced datasets where both false positives and false negatives are important.\n","   - **Avoid**: If precision or recall is significantly more critical than the other.\n","\n"],"metadata":{"id":"K4JgB5KznTRO"}},{"cell_type":"markdown","source":["__Exercise__\n","\n","Return to the previous notebooks where we performed binary and multiclass classification. For each task:\n","\n","Print the confusion matrix to visualize the classification outcomes.Then determine which performance metrics (accuracy, precision, recall, F1 score) are most appropriate for evaluating each task. Justify your choice of metrics (e.g., imbalanced classes, focus on minimizing false positives, etc.). Finally, interpret the results of the metrics you’ve chosen. For example, determine if the model good at identifying certain classes or if there are issues with false positives or false negatives."],"metadata":{"id":"1uM0wS7FxZxY"}},{"cell_type":"code","source":[],"metadata":{"id":"UK-n11PdygJA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"QW0hJLTX2v93"},"execution_count":null,"outputs":[]}]}